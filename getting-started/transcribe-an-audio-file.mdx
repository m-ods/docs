---
title: "Transcribe an Audio File"
description: Learn how to transcribe and analyze an audio file.
---

<Note>
Universal-2 is live
Dive into our research paper to see how we're redefining speech AI accuracy. Read more [here](https://www.assemblyai.com/research/universal-2).
</Note>

## Overview[​](#overview "Direct link to Overview")

By the end of this tutorial, you'll be able to:

*   Transcribe an audio file.
*   Enable [Speaker Diarization](/docs/speech-to-text/speaker-diarization) to detect speakers in an audio file.

Here's the full sample code for what you'll build in this tutorial:

<CodeGroup>

```python Python
import assemblyai as aai

aai.settings.api_key = "YOUR_API_KEY"

transcriber = aai.Transcriber()

# You can use a local filepath:
# audio_file = "./example.mp3"

# Or use a publicly-accessible URL:
audio_file = (
    "https://assembly.ai/sports_injuries.mp3"
)

config = aai.TranscriptionConfig(speaker_labels=True)

transcript = transcriber.transcribe(audio_file, config)

if transcript.status == aai.TranscriptStatus.error:
    print(f"Transcription failed: {transcript.error}")
    exit(1)

print(transcript.text)

for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
```

```typescript typescript
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: 'YOUR_API_KEY'
})

// You can use a local filepath:
// const audioFile = "./example.mp3"

// Or use a publicly-accessible URL:
const audioFile = 'https://assembly.ai/sports_injuries.mp3'

const params = {
  audio: audioFile,
  speaker_labels: true
}

const run = async () => {
  const transcript = await client.transcripts.transcribe(params)

  if (transcript.status === 'error') {
    console.error(`Transcription failed: ${transcript.error}`)
    process.exit(1)
  }

  console.log(transcript.text)

  for (let utterance of transcript.utterances!) {
    console.log(`Speaker ${utterance.speaker}: ${utterance.text}`)
  }
}

run()
```

```go Go
package main

import (
    "context"
    "fmt"
    "os"

    aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
    ctx := context.Background()

    client := aai.NewClient("YOUR_API_KEY")

    params := &aai.TranscriptOptionalParams{
        SpeakerLabels: aai.Bool(true),
    }

    // You can use a local file:
    /*
    f, err := os.Open("./example.mp3")
    [error handling here]
    transcript, err := client.Transcripts.TranscribeFromReader(ctx, f, params)
    */

    // Or use a publicly-accessible URL:
    audioURL := "https://assembly.ai/sports_injuries.mp3"

    transcript, err := client.Transcripts.TranscribeFromURL(ctx, audioURL, params)
    if err != nil {
        fmt.Println("Something bad happened:", err)
        os.Exit(1)
    }

    fmt.Println(*transcript.Text)

    for _, utterance := range transcript.Utterances {
        fmt.Printf("Speaker %v: %v\n", *utterance.Speaker, *utterance.Text)
    }
}
```

```java Java
import com.assemblyai.api.AssemblyAI;
import com.assemblyai.api.resources.transcripts.types.*;

public final class App {
    public static void main(String[] args) {
        AssemblyAI client = AssemblyAI.builder()
                .apiKey("YOUR_API_KEY")
                .build();

        var params = TranscriptOptionalParams.builder()
                .speakerLabels(true)
                .build();

        // You can use a local file:
        /*
        Transcript transcript = aai.transcripts().transcribe(
                new File("./example.mp3"), params);
        */

        // Or use a publicly-accessible URL:
        String audioUrl = "https://assembly.ai/sports_injuries.mp3";
        Transcript transcript = client.transcripts().transcribe(audioUrl, params);

        if (transcript.getStatus().equals(TranscriptStatus.ERROR)) {
          System.err.println(transcript.getError().get());
          System.exit(1);
        }

        System.out.println(transcript.getText().get());

        transcript.getUtterances().get().forEach(utterance ->
                System.out.println("Speaker " + utterance.getSpeaker() + ": " + utterance.getText())
        );
    }
}
```

</CodeGroup>

## Before you begin[​](#before-you-begin "Direct link to Before you begin")

To complete this tutorial, you need:

*   [Python](https://www.python.org/), [TypeScript](https://www.typescriptlang.org/), [Go](https://go.dev), Java, [.NET](https://dotnet.microsoft.com/en-us/download), or [Ruby](https://www.ruby-lang.org/en/documentation/installation/) installed.
*   A [free AssemblyAI account](https://www.assemblyai.com/dashboard/signup).

## Step 1: Install the SDK[​](#step-1-install-the-sdk "Direct link to Step 1: Install the SDK")

<CodeGroup>

```sh Python
pip install assemblyai
```

```sh Typescript
npm install assemblyai
```

</CodeGroup>

## Step 2: Configure the SDK[​](#step-2-configure-the-sdk "Direct link to Step 2: Configure the SDK")

In this step, you 'll create an SDK client and configure it to use your API key.

1. Browse to [Account](https://www.assemblyai.com/app/account), and then click the text under **Your API key** to copy it.
2. Create a new `Transcriber` and configure it to use your API key. Replace `YOUR_API_KEY` with your copied API key.
    
<CodeGroup>

```python Python
import assemblyai as aai

aai.settings.api_key = "YOUR_API_KEY"

transcriber = aai.Transcriber()
```

```typescript Typescript
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: 'YOUR_API_KEY'
})
```

</CodeGroup>
    

## Step 3: Submit audio for transcription[​](#step-3-submit-audio-for-transcription "Direct link to Step 3: Submit audio for transcription")

In this step, you'll submit the audio file for transcription and wait until it's completes. The time it takes to process an audio file depends on its duration and the enabled models. Most transcriptions complete within 45 seconds.

1. Specify a URL to the audio you want to transcribe. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](/docs/Concepts/faq).

<CodeGroup>

```python Python
audio_file = "https://assembly.ai/sports_injuries.mp3"
```

```typescript Typescript
const audioFile = 'https://assembly.ai/sports_injuries.mp3'
```

</CodeGroup>
    
<Info>
Local audio files
    
If you want to use a local file, you can also specify a local path, for example:

```python
audio_file = "./example.mp3"
```
</Info>

<Info>
YouTube

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.
</Info>
    
2. To generate the transcript, pass the audio URL to `transcribe()`.
    
    This may take a minute while we're processing the audio.

<CodeGroup>

```python Python
transcript = transcriber.transcribe(audio_file)
```

```typescript Typescript
const transcript = await client.transcripts.transcribe({ audio: audioFile })
```

</CodeGroup>

<Info>
Select the speech model
    
You can select the class of models to use in order to make cost-performance tradeoffs best suited for your application. See [Select the speech model](/docs/speech-to-text/speech-recognition#select-the-speech-model-with-best--nano).
</Info>
    
3. If the transcription failed, the `status` of the transcription will be set to `error`. To see why it failed you can print the value of `error`.

<CodeGroup>

```python Python
if transcript.error:   
    print(transcript.error)   
    exit(1)
```

```typescript Typescript
if (transcript.status === 'error') {  
    console.error(transcript.error)  
    process.exit(1)
}
```

</CodeGroup>
    
4. Print the complete transcript.

<CodeGroup>

```python Python
print(transcript.text)
```

```typescript Typescript
console.log(transcript.text)
```

</CodeGroup>
    
5. Run the application and wait for it to finish.
    

You've successfully transcribed your first audio file. You can see all submitted transcription jobs in the [Processing queue](https://www.assemblyai.com/app/processing-queue).

## Step 4: Enable additional AI models[​](#step-4-enable-additional-ai-models "Direct link to Step 4: Enable additional AI models")

You can extract even more insights from the audio by enabling any of our [AI models](/docs/audio-intelligence) using _transcription options_. In this step, you'll enable the [Speaker diarization](/docs/speech-to-text/speaker-diarization) model to detect who said what.

1. Create a `TranscriptionConfig` with `speaker_labels` set to `True`, and then pass it as the second argument to `transcribe()`.

<CodeGroup>

```python Python
config = aai.TranscriptionConfig(speaker_labels=True)
transcript = transcriber.transcribe(audio_file, config)
```

```typescript Typescript
const params = {  audio: audioFile,  speaker_labels: true}
const transcript = await client.transcripts.transcribe(params)
```

</CodeGroup>
    
2. In addition to the full transcript, you now have access to utterances from each speaker.

<CodeGroup>

```python Python
for utterance in transcript.utterances:    
    print(f"Speaker {utterance.speaker}: {utterance.text}")
```

```typescript Typescript
for (let utterance of transcript.utterances!) {  
    console.log(`Speaker ${utterance.speaker}: ${utterance.text}`)
}
```

</CodeGroup>

Many of the properties in the transcript object only become available after you enable the corresponding model. For more information, see the models under [Speech-to-Text](/docs/speech-to-text) and [Audio Intelligence](/docs/audio-intelligence).

## Next steps[​](#next-steps "Direct link to Next steps")

In this tutorial, you've learned how to generate a transcript for an audio file and how to extract speaker information by enabling the [Speaker diarization](/docs/speech-to-text/speaker-diarization) model.

Want to learn more?

*   For more ways to analyze your audio data, explore our [Audio Intelligence models](/docs/audio-intelligence).
*   If you want to transcribe audio in real-time, see [Transcribe streaming audio from a microphone](/docs/getting-started/transcribe-streaming-audio-from-a-microphone).
*   To search, summarize, and ask questions on your transcripts with LLMs, see [LeMUR](/docs/lemur).

## Need some help?[​](#need-some-help "Direct link to Need some help?")

If you get stuck, or have any other questions, we'd love to help you out. Ask our support team in our [Discord server](https://discord.gg/aSMMpMadFh).