---
title: "ü¶úÔ∏èüîó LangChain Python Integration with AssemblyAI"
description: "To apply LLMs to speech, you first need to transcribe the audio to text, which is what the AssemblyAI integration for LangChain helps you with."
---

<Note>
  Looking for the LangChain JavaScript/TypeScript integration? [Go to the LangChain.JS integration](/integrations/langchain/js).
</Note>

## Quickstart[‚Äã](#quickstart "Direct link to Quickstart")

Install [the AssemblyAI package](https://github.com/langchain-ai/langchain) and [the AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk):

```
pip install langchainpip install assemblyai
```

Set your AssemblyAI API key as an environment variable named `ASSEMBLYAI_API_KEY`. You can [get a free AssemblyAI API key from the AssemblyAI dashboard](https://www.assemblyai.com/dashboard/signup).

```
# Mac/Linux:export ASSEMBLYAI_API_KEY=YOUR_API_KEY # Windows:set ASSEMBLYAI_API_KEY=YOUR_API_KEY 
```

Import the `AssemblyAIAudioTranscriptLoader` from `langchain.document_loaders`.

```
from langchain.document_loaders import AssemblyAIAudioTranscriptLoader
```

1. Pass the local file path or URL as the `file_path` argument of the `AssemblyAIAudioTranscriptLoader`.
2. Call the `load` method to get the transcript as LangChain documents.

```
audio_file = "https://assembly.ai/sports_injuries.mp3"# or a local file path: audio_file = "./sports_injuries.mp3"loader = AssemblyAIAudioTranscriptLoader(file_path=audio_file)docs = loader.load()
```

The `load` method returns an array of documents, but by default, there's only one document in the array with the full transcript.

The transcribed text is available in the `page_content` attribute:

```
docs[0].page_content# Load time, a new president and new congressional makeup. Same old ...
```

The `metadata` contains the full JSON response with more meta information:

```
{  'language_code': <LanguageCode.en_us: 'en_us'>,  'audio_url': 'https://assembly.ai/nbc.mp3',  'punctuate': True,  'format_text': True,  ...}
```

## Transcript formats[‚Äã](#transcript-formats "Direct link to Transcript formats")

You can specify the `transcript_format` argument to load the transcript in different formats.

Depending on the format, `load_data()` returns either one or more documents. These are the different `TranscriptFormat` options:

* `TEXT`: One document with the transcription text
* `SENTENCES`: Multiple documents, splits the transcription by each sentence
* `PARAGRAPHS`: Multiple documents, splits the transcription by each paragraph
* `SUBTITLES_SRT`: One document with the transcript exported in SRT subtitles format
* `SUBTITLES_VTT`: One document with the transcript exported in VTT subtitles format

```
from langchain.document_loaders.assemblyai import TranscriptFormatloader = AssemblyAIAudioTranscriptLoader(    file_path="./your_file.mp3",    transcript_format=TranscriptFormat.SENTENCES,)docs = loader.load()
```

## Transcription config[‚Äã](#transcription-config "Direct link to Transcription config")

You can also specify the `config` argument to use different transcript features and audio intelligence models. Here's an example of using the `config` argument to enable speaker labels, auto chapters, and entity detection:

```
import assemblyai as aaiconfig = aai.TranscriptionConfig(    speaker_labels=True, auto_chapters=True, entity_detection=True)loader = AssemblyAIAudioTranscriptLoader(file_path="./your_file.mp3", config=config)
```

<Info>
  For the full list of options, see [Transcript API reference](https://assemblyai.com/docs/api-reference/transcripts/submit#request).
</Info>

## Pass the AssemblyAI API key as an argument[‚Äã](#pass-the-assemblyai-api-key-as-an-argument "Direct link to Pass the AssemblyAI API key as an argument")

Instead of configuring the AssemblyAI API key as the `ASSEMBLYAI_API_KEY` environment variable, you can also pass it as the `api_key` argument.

```
loader = AssemblyAIAudioTranscriptLoader(    file_path="./your_file.mp3", api_key="YOUR_API_KEY" )
```

## Additional resources[‚Äã](#additional-resources "Direct link to Additional resources")

You can learn more about using LangChain with AssemblyAI in these resources.

* [LangChain docs for the AssemblyAI document loader](https://python.langchain.com/docs/integrations/document_loaders/assemblyai)
* [How to use audio data in LangChain with Python](https://www.assemblyai.com/blog/load-audio-langchain-python/)
* [Retrieval Augmented Generation on audio data with LangChain and Chroma](https://www.assemblyai.com/blog/retrieval-augmented-generation-audio-langchain/)
* [Build LangChain Audio Apps with Python in 5 Minutes](https://www.youtube.com/watch?v=7w7ysaDz2W4)
* [How to use LangChain for RAG over audio files](https://www.youtube.com/watch?v=l9YJrLg61ac)
* [AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk)
