---
title: "Zapier Integration with AssemblyAI"
description: "Zapier is a workflow automation tool that lets you integrate various services together without requiring coding knowledge. You can use our AI models to process audio data by transcribing it with speech recognition models and analyzing it with audio intelligence models. You can supply audio to the AssemblyAI app and connect the output of our models to other services in your Zaps."
---

## Quickstart[​](#quickstart "Direct link to Quickstart")

1. 1

   In your Zap editor, add an action, search for `AssemblyAI` and select the AssemblyAI app.

   ![Change action Zapier screen, with AssemblyAI in search box.](/images/docs/integrations/docs/assets/images/1-change-action-4b2c2fae4a1853758c8be8b6de393319.png)

2. 2

   Next, configure the action. In the **App & event** tab, select **Transcribe** for the **Event** dropdown, then click **Continue**.

   ![App \&amp; event Zapier tab with Event field set to \&quot;Transcribe\&quot;.](/images/docs/integrations/docs/assets/images/2-app-event-7b0be363cf636bd5f5ff364827fda723.png)

3. 3

   Then, in the **Account** tab, click **Sign in** which will open a separate window. In the window, enter your AssemblyAI API key in **API Key** field, and click **Yes, Continue to AssemblyAI**. Back in the Zap editor, click **Continue**.

   ![Account Zapier tab where you are prompted to Connect AssemblyAI with a Sign in button.](/images/docs/integrations/docs/assets/images/3-account-fa4ece3b3215b649eef7bb80630e10b3.png)

4. 4

   In the **Action** tab, enter the URL of the audio or video file you want to transcribe in the **Audio URL** field. The URL has to be publicly accessible. Click **Continue**.

   ![Action Zapier tab where you are prompted to enter the Audio URL to transcribe using AssemblyAI.](/images/docs/integrations/docs/assets/images/4-action-8d640ee36b1f0b547ac2b721a7b436f8.png)

5. 5

   Finally, you can test the action. You can use all the fields returned by the action in subsequent steps.

   <Note>
     All AssemblyAI actions return sample data during testing instead of running the action. This makes it easier to build your Zaps, however, you have to test using normal Zap runs to verify everything is working correctly. Learn more about why we [return sample data during testing below](#testing-with-sample-data).
   </Note>

   ![Test Zapier tab where you can see the output of the AssemblyAI Transcribe action.](/images/docs/integrations/docs/assets/images/5-test-369f5171a1e4361846dd101a869cd608.png)

## Zapier Actions[​](#zapier-actions "Direct link to Zapier Actions")

### Transcribe[​](#transcribe "Direct link to Transcribe")

Transcribe an audio file and wait until the transcript has completed or failed. Configure the `Audio URL` field with the URL of the audio file you want to transcribe. The `Audio URL` must be accessible by AssemblyAI's servers.

If you don't want to wait until the transcript is ready, change the `Wait until Transcript is Ready` parameter to `False`.

### Get Transcript[​](#get-transcript "Direct link to Get Transcript")

Retrieves a transcript by its ID.

### Get Transcript Subtitles[​](#get-transcript-subtitles "Direct link to Get Transcript Subtitles")

Export the transcript as SRT or VTT subtitles.

<Note>
  You can only invoke this action after the transcript is completed.
</Note>

### Get Transcript Sentences[​](#get-transcript-sentences "Direct link to Get Transcript Sentences")

Retrieve the sentences of the transcript by its ID.

<Note>
  You can only invoke this action after the transcript is completed.
</Note>

### Get Transcript Paragraphs[​](#get-transcript-paragraphs "Direct link to Get Transcript Paragraphs")

Retrieve the paragraphs of the transcript by its ID.

<Note>
  You can only invoke this action after the transcript is completed.
</Note>

### Get Transcript Redacted Audio Result[​](#get-transcript-redacted-audio-result "Direct link to Get Transcript Redacted Audio Result")

Get the result of the redacted audio model.

<Note>
  You can only invoke this action after the transcript is completed.
</Note>

### What about LeMUR?[​](#what-about-lemur "Direct link to What about LeMUR?")

Unfortunately, the Zapier platform doesn't have the necessary features for us to reliably offer LeMUR, our LLM framework for speech understanding. We're looking at different avenues to add support in the future, but we have no timeline for when LeMUR support will be available.

## Testing with sample data[​](#testing-with-sample-data "Direct link to Testing with sample data")

A transcript goes through multiple phases to transcribe audio, reflected by different statuses. The initial status is `queued`, immediately followed by `processing`, and the final status is either `completed` or `error`. **During a normal Zap run**, the Transcribe event will wait until the transcript status is `completed`, and throw an error if the status is `error`. Unfortunately, this is not the case during testing.

Because of a Zapier platform limitation, **during testing**, the Transcribe event will return a transcript with the `queued` status. A transcript that does not have the `completed` status cannot be used in subsequent tests.

This way you can easily test using sample data, but you still have to use normal Zap runs to verify the end-to-end functionality.

## Additional resources[​](#additional-resources "Direct link to Additional resources")

You can learn more about using Zapier with AssemblyAI in these resources:

* [How to generate subtitles for your videos using the AssemblyAI app for Zapier](https://www.assemblyai.com/blog/generate-subtitles-with-zapier)
* [How to get started with AssemblyAI on Zapier](https://help.zapier.com/hc/en-us/articles/16411509681933-How-to-get-started-with-AssemblyAI-on-Zapier)
* [AssemblyAI app on Zapier](https://zapier.com/apps/assemblyai/integrations)
